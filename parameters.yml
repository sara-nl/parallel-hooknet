## data:
data_path: './data'         # path to data folder
output_path: './output'     # path were output will be saved (e.g, the weights of the model)

# model
input_shape: [284, 284, 3]  # input shape of the model
n_classes: 2                # output classes of the model
resolutions: [0.5, 2.0]     # input resolutions of the model [target, context]
hook_indexes: [3, 3]        # the respective depths (starting from 0) of hooking [from, to] in the decoders
n_convs: 2                  # the number of 2D convolutions per convolutional block
depth: 4                    # the depth of the encoder-decoder branches
n_filters: 16               # the number of starting filters (will be increased and decreased by a factor 2 in each conv block in the encoders and decoders, respectively)
filter_size: 3              # the size of the filter in a 2D convolution
padding: 'valid'            # padding type in 2D convolution (either 'same' or 'valid')
batch_norm: true            # boolean for using batch normalization
activation: 'relu'          # activation function applied after 2D convolution
learning_rate: 0.000005     # learning rate of the optimizer
l2_lambda: 0.0001           # l2 value for regulizer 
opt_name: 'adam'            # optimizer name (either 'sgd' or 'adam')
loss_weights: [0.5, 0.5]    # loss contribution for each branch [target, context]
merge_type: 'concat'        # method used for combining feature maps (either 'concat', 'add', 'subtract', 'multiply')

# train 
epochs: 2                   # The number of epochs the trainer will run
steps: 100                    # The number of steps (i.e., batches) in an epoch
batch_size: 16              # The number of examples in one batch

# system
seed: 123                   # seed value for random python and numpy parts