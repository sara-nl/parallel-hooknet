{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(inputs, out_channels, name='conv'):\n",
    "    conv = tf.layers.conv2d(inputs, out_channels, kernel_size=3, padding='SAME')\n",
    "    conv = tf.contrib.layers.batch_norm(conv, updates_collections=None, decay=0.99, scale=True, center=True)\n",
    "    conv = tf.nn.relu(conv)\n",
    "    conv = tf.contrib.layers.max_pool2d(conv, 2)\n",
    "    return conv\n",
    "\n",
    "def encoder(support_set, h_dim, z_dim, reuse=False):\n",
    "    net = convolution_block(support_set, h_dim, name='conv_1')\n",
    "    net = convolution_block(net, h_dim, name='conv_2')\n",
    "    net = convolution_block(net, h_dim, name='conv_3')\n",
    "    net = convolution_block(net, z_dim, name='conv_4')\n",
    "    net = tf.contrib.layers.flatten(net)\n",
    "    return net\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    N, D = tf.shape(a)[0], tf.shape(a)[1]\n",
    "    M = tf.shape(b)[0]\n",
    "    a = tf.tile(tf.expand_dims(a, axis=1), (1, M, 1))\n",
    "    b = tf.tile(tf.expand_dims(b, axis=0), (N, 1, 1))\n",
    "    return tf.reduce_mean(tf.square(a - b), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "support_set = tf.placeholder(tf.float32, [None, None, img_height, img_width, channels])\n",
    "query_set = tf.placeholder(tf.float32, [None, None, img_height, img_width, channels])\n",
    "support_set_shape = tf.shape(support_set)\n",
    "query_set_shape = tf.shape(query_set)\n",
    "num_classes, num_support_points = support_set_shape[0], support_set_shape[1]\n",
    "num_query_points = query_set_shape[1]\n",
    "y = tf.placeholder(tf.int64, [None, None])\n",
    "y_one_hot = tf.one_hot(y, depth=num_classes)\n",
    "support_set_embeddings = encoder(tf.reshape(support_set, [num_classes * num_support_points, img_height, img_width, channels]), h_dim, z_dim)\n",
    "embedding_dimension = tf.shape(support_set_embeddings)[-1]\n",
    "class_prototype = tf.reduce_mean(tf.reshape(support_set_embeddings, [num_classes, num_support_points, embedding_dimension]), axis=1)\n",
    "query_set_embeddings = encoder(tf.reshape(query_set, [num_classes * num_query_points, img_height, img_width, channels]), h_dim, z_dim, reuse=True)\n",
    "distance = euclidean_distance(query_set_embeddings, class_prototype)\n",
    "predicted_probability = tf.reshape(tf.nn.log_softmax(-distance), [num_classes, num_query_points, -1])\n",
    "loss = -tf.reduce_mean(tf.reshape(tf.reduce_sum(tf.multiply(y_one_hot, predicted_probability), axis=-1), [-1]))\n",
    "accuracy = tf.reduce_mean(tf.to_float(tf.equal(tf.argmax(predicted_probability, axis=-1), y)))\n",
    "\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for episode in range(num_episodes):\n",
    "\n",
    "        x_batch, _ = generator.batch('training')\n",
    "        splits = np.array(np.array_split(x_batch, num_way))\n",
    "        support, query = np.array_split(splits,[1], axis=1)\n",
    "\n",
    "        labels = np.tile(np.arange(num_way)[:, np.newaxis], (1, num_query)).astype(np.uint8)\n",
    "        _, loss_, accuracy_ = sess.run([train_op, loss, accuracy], feed_dict={support_set: support, query_set: query, y:labels})\n",
    "\n",
    "        if (episode+1) % 10 == 0:\n",
    "            print('Epoch {} : Episode {} : Loss: {}, Accuracy: {}'.format(epoch+1, episode+1, loss_, accuracy_))\n",
    "\n",
    "\n",
    "            \n",
    "# print('Testing...')\n",
    "\n",
    "# avg_acc = 0.\n",
    "# for epi in range(n_test_episodes):\n",
    "#     epi_classes = np.random.permutation(x_test_classes)[:n_test_way]\n",
    "#     support = np.zeros([n_test_way, n_test_shot, img_height, img_width], dtype=np.float32)\n",
    "#     query = np.zeros([n_test_way, n_test_query, img_height, img_width], dtype=np.float32)\n",
    "#     for i, epi_cls in enumerate(epi_classes):\n",
    "#         selected = np.random.permutation(num_examples)[:n_test_shot + n_test_query]\n",
    "#         support[i] = x_test[epi_cls, selected[:n_test_shot]]\n",
    "#         query[i] = x_test[epi_cls, selected[n_test_shot:]]\n",
    "#     support = np.expand_dims(support, axis=-1)\n",
    "#     query = np.expand_dims(query, axis=-1)\n",
    "#     labels = np.tile(np.arange(n_test_way)[:, np.newaxis], (1, n_test_query)).astype(np.uint8)\n",
    "#     ls, ac = sess.run([loss, accuracy], feed_dict={support_set: support, query_set: query, y:labels})\n",
    "#     avg_acc += ac\n",
    "#     if (epi+1) % 50 == 0:\n",
    "#         print('[test episode {}/{}] => loss: {:.5f}, acc: {:.5f}'.format(epi+1, n_test_episodes, ls, ac))\n",
    "# avg_acc /= n_test_episodes\n",
    "# print('Average Test Accuracy: {:.5f}'.format(avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as keras, regularizers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, UpSampling2D, Cropping2D, concatenate, Input, Reshape, AveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width, channels = 128,128,3\n",
    "support_set = Input([None, img_height, img_width, channels])\n",
    "query_set = Input([None, img_height, img_width, channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "one_hot() missing 2 required positional arguments: 'indices' and 'depth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3778bacadc0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mart/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: one_hot() missing 2 required positional arguments: 'indices' and 'depth'"
     ]
    }
   ],
   "source": [
    "y_one_hot = tf.one_hot(y, depth=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
